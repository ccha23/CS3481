{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS3481 Tutorial 9",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3AzlVAZkPCo",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial 9\n",
        "\n",
        "**CS3481 Fundamentals of Data Science**\n",
        "\n",
        "*Semester B 2019/20*\n",
        "___\n",
        "**Instructions:**\n",
        "- same as [Tutorial 1](http://bit.ly/CS3481T1).\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tEsb8F0sFdP",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1 (submit via [uReply](https://cityu.ed2.mobi/student/mobile_index.php) section number **LM1100**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq9eL_urVOKc",
        "colab_type": "text"
      },
      "source": [
        "For this question, you will use WEKA to analyze a skewed dataset. \n",
        "1. Download the mamography dataset from [OpenML](https://www.openml.org/d/310).<br>\n",
        "Woods, Kevin S., et al. \"Comparative evaluation of pattern recognition techniques for detection of microcalcifications.\" Biomedical Image Processing and Biomedical Visualization. Vol. 1905. International Society for Optics and Photonics, 1993. [(Available via CityU VPN.)](https://www.worldscientific.com/doi/abs/10.1142/9789812797834_0011) The following is the description of the dataset excerpted from the paper:\n",
        "\n",
        "  > To obtain the training and test data, a segmentation routine is run on a set of digitized mammograms. The result of the segmentation routine is a template for each image which indicates the locations of possible microcalcifications called candidates. The segmentation routine is designed to locate small, bright spots (a characteristic of microcalcifications) in the raw image. It is important that most individual calcifications and all clusters of calcifications be segmented since the overall cluster detection accuracy can be limited by the results of the segmentation. Since the segmentation routine will detect objects other than microcalcifications, it is the job of the classifiers to label the candidates as either yes (a microcalcification) or no. A set of 7 features is systematically chosen and values are computed for each candidate. The feature values are organized into a feature vector, normalized, and written to a data file. Therefore, the training and test data is 7-dimensional feature vectors which are normalized between 0 and 1 using the (value-min)/(max-min) formula, where value is the feature vector element being normalized, and max and min are the maximum and minimum training set values for that feature.\n",
        "\n",
        "2. Use the package manager to download a meta classifier called `ThresholdSelector`, and a filter `SMOTE` [Synthetic Minority Over-sampling Technique](https://doi.org/10.1613/jair.953). \n",
        "\n",
        "Your goal is to detect microcalcifications in the mammographic images. Use $10$-fold stratified cross validation and a random seed of $1$ unless otherwise stated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFk7jQnlVjQW",
        "colab_type": "text"
      },
      "source": [
        "(a) Using ZeroR as the classifier, obtain the values of accuracy, precision, recall, and specificity. Verify the values by hand calculations. Is ZeroR a good baseline classifier?\n",
        "\n",
        "[*Hint: Is the accuracy misleading? Can a random decision maker do better than zeroR?*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4uZljouV066",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "**Answer:**\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m85_hnOGWA9w",
        "colab_type": "text"
      },
      "source": [
        "(b) Using J48 as the classifier instead, obtain the values of accuracy, precision, recall, and the F-score. Verify the value by hand calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVlfulG3WwK-",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "**Answer:**\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LMPOs44OL-Nd"
      },
      "source": [
        "## Exercise 2 (submit via Canvas discussion page)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoxJGvitt0yx",
        "colab_type": "text"
      },
      "source": [
        "For this question, your goal is to obtain the best performance and post your model and results on the [discussion page](https://canvas.cityu.edu.hk/courses/32828/discussion_topics/254800)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rxBxgP0wiCNK"
      },
      "source": [
        "(a) In the result list, right click on your result using J48 as the classifier and choose Cost/Benefit analysis and $1$ as the positive class value. Your goal is to find the maximum value of the precision. Give a cost matrix that achieves the maximum precision.\n",
        "    \n",
        "[*Hint: Pay attention to the row and column labels of the confusion matrix. It changes after you specify $1$ as the positive class value.*] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zkvpzLm6iCNM"
      },
      "source": [
        "___\n",
        "**Answer:**\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lQTLHLt3ikMp"
      },
      "source": [
        "(b) The meta classifier ThresholdSelector uses the threshold-moving technique to optimize a performance measure you specify, which can be the precision, recall, $F$ score, etc. Use J48 as the base classifier, obtain the highest precision, recall and $F$ score reported. Is any of these scores equal to $100\\%$?\n",
        "\n",
        "[*Hint: See an explanation of threshold moving technique [here](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/).*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GDmZk0_WikMr"
      },
      "source": [
        "___\n",
        "**Answer:**\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0mA5GjujJUB",
        "colab_type": "text"
      },
      "source": [
        "(c) Using the FilteredClassifier with J48 as the classifer and SMOTE as the filter, try to tweek the setting of SMOTE to give the highest possilbe value of $F$ score you can get.\n",
        "\n",
        "[*See an explanation of SMOTE [here](http://rikunert.com/SMOTE_explained).*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWHeD694h_lT"
      },
      "source": [
        "___\n",
        "**Answer:**\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUx5dPQDlqIo",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3 (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjxybv2sxJYl",
        "colab_type": "text"
      },
      "source": [
        "Load the dataset from OpenML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKx6TfJHxN06",
        "colab_type": "code",
        "outputId": "69b3ded7-9f54-4563-999a-a11806441933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "mammo = fetch_openml(data_id=310)\n",
        "mammo_pd = pd.DataFrame(data=np.c_[mammo.data,mammo.target],columns=mammo.feature_names+['target'])\n",
        "mammo_pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attr1</th>\n",
              "      <th>attr2</th>\n",
              "      <th>attr3</th>\n",
              "      <th>attr4</th>\n",
              "      <th>attr5</th>\n",
              "      <th>attr6</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23002</td>\n",
              "      <td>5.07258</td>\n",
              "      <td>-0.276061</td>\n",
              "      <td>0.832444</td>\n",
              "      <td>-0.377866</td>\n",
              "      <td>0.480322</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.155491</td>\n",
              "      <td>-0.16939</td>\n",
              "      <td>0.670652</td>\n",
              "      <td>-0.859553</td>\n",
              "      <td>-0.377866</td>\n",
              "      <td>-0.945723</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.784415</td>\n",
              "      <td>-0.443654</td>\n",
              "      <td>5.67471</td>\n",
              "      <td>-0.859553</td>\n",
              "      <td>-0.377866</td>\n",
              "      <td>-0.945723</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.546088</td>\n",
              "      <td>0.131415</td>\n",
              "      <td>-0.456387</td>\n",
              "      <td>-0.859553</td>\n",
              "      <td>-0.377866</td>\n",
              "      <td>-0.945723</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.102987</td>\n",
              "      <td>-0.394994</td>\n",
              "      <td>-0.140816</td>\n",
              "      <td>0.979703</td>\n",
              "      <td>-0.377866</td>\n",
              "      <td>1.01357</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11178</th>\n",
              "      <td>-0.250012</td>\n",
              "      <td>-0.3773</td>\n",
              "      <td>-0.321142</td>\n",
              "      <td>1.26916</td>\n",
              "      <td>3.65298</td>\n",
              "      <td>1.09279</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11179</th>\n",
              "      <td>0.281343</td>\n",
              "      <td>-0.417112</td>\n",
              "      <td>-0.366224</td>\n",
              "      <td>0.85101</td>\n",
              "      <td>2.78965</td>\n",
              "      <td>1.3457</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11180</th>\n",
              "      <td>1.20499</td>\n",
              "      <td>1.76372</td>\n",
              "      <td>-0.501468</td>\n",
              "      <td>1.56241</td>\n",
              "      <td>6.48907</td>\n",
              "      <td>0.931294</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11181</th>\n",
              "      <td>0.736644</td>\n",
              "      <td>-0.222474</td>\n",
              "      <td>-0.0506528</td>\n",
              "      <td>1.50966</td>\n",
              "      <td>0.539269</td>\n",
              "      <td>1.31523</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11182</th>\n",
              "      <td>0.177003</td>\n",
              "      <td>-0.191508</td>\n",
              "      <td>-0.501468</td>\n",
              "      <td>1.57886</td>\n",
              "      <td>7.7507</td>\n",
              "      <td>1.55595</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11183 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          attr1     attr2      attr3     attr4     attr5     attr6 target\n",
              "0       0.23002   5.07258  -0.276061  0.832444 -0.377866  0.480322     -1\n",
              "1      0.155491  -0.16939   0.670652 -0.859553 -0.377866 -0.945723     -1\n",
              "2     -0.784415 -0.443654    5.67471 -0.859553 -0.377866 -0.945723     -1\n",
              "3      0.546088  0.131415  -0.456387 -0.859553 -0.377866 -0.945723     -1\n",
              "4     -0.102987 -0.394994  -0.140816  0.979703 -0.377866   1.01357     -1\n",
              "...         ...       ...        ...       ...       ...       ...    ...\n",
              "11178 -0.250012   -0.3773  -0.321142   1.26916   3.65298   1.09279      1\n",
              "11179  0.281343 -0.417112  -0.366224   0.85101   2.78965    1.3457      1\n",
              "11180   1.20499   1.76372  -0.501468   1.56241   6.48907  0.931294      1\n",
              "11181  0.736644 -0.222474 -0.0506528   1.50966  0.539269   1.31523      1\n",
              "11182  0.177003 -0.191508  -0.501468   1.57886    7.7507   1.55595      1\n",
              "\n",
              "[11183 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E71dD3IP31bc",
        "colab_type": "text"
      },
      "source": [
        "Import the libraries for decision tree, ROC analysis, and cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q10_FZPG38-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.metrics import auc, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9z0Y0PmGQv_",
        "colab_type": "text"
      },
      "source": [
        "Split the data into training and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZHuXaErFaW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = mammo_pd.iloc[:,:-1]\n",
        "Y = mammo_pd.iloc[:,-1]\n",
        "trainX, testX, trainY, testY = train_test_split(X,Y,test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "536OokpVGVvT",
        "colab_type": "text"
      },
      "source": [
        "Train the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aChfWffoFYdG",
        "colab_type": "code",
        "outputId": "cd44e160-22c4-4e58-bc28-c06754655618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "clf_gini = tree.DecisionTreeClassifier() \n",
        "clf_gini.fit(trainX,trainY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnOzrkqiIRiB",
        "colab_type": "text"
      },
      "source": [
        "To compute the ROC curve (TPR and FPR), the classifer should return soft decisions on the test data in the form of probabilities for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_jMNB0YGhBn",
        "colab_type": "code",
        "outputId": "ec2b5442-408a-4ce5-89d3-8021a84d083e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "prob = clf_gini.predict_proba(testX)\n",
        "prob_pos = prob[:,clf_gini.classes_=='1']\n",
        "fpr, tpr, _ = roc_curve(testY,prob_pos,'1')\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Decision tree')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1ac02d25c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-mcbPh0J0Jc",
        "colab_type": "text"
      },
      "source": [
        "Compute the AUC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adxKp2BcJzuq",
        "colab_type": "code",
        "outputId": "ff99c492-24f7-4adf-83ab-73ae29666760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "roc_auc = roc_auc_score(testY,prob_pos)\n",
        "print(\"ROC AUC: {:.2f}\".format(roc_auc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtKiUuH3J79H",
        "colab_type": "text"
      },
      "source": [
        "**Exercise:** Why does the ROC curve contain only a few points? \n",
        "\n",
        "[*Hint: Check the number of distinct probabilities in `prob_pos`.*]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWaQO3t1KGJo",
        "colab_type": "text"
      },
      "source": [
        "**Exercise:** Repeat the analysis for PR curve instead using [`pr_curve` and `pr_auc_score`](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAbYkZyKjbm5",
        "colab_type": "text"
      },
      "source": [
        "**Exercise:** Repeat the analysis with Cross-validation using [`plot_roc_curve`](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html) instead."
      ]
    }
  ]
}